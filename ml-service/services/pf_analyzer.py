"""
Plantar Fasciitis Analyzer (Research Based - Tuned)
‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: Lucas et al., 2018 (MBE + Perimeter)
"""

import httpx
import asyncio
from typing import List, Dict, Any
import logging
import numpy as np
import cv2

logger = logging.getLogger(__name__)

class PlantarFasciitisAnalyzer:
    def __init__(self):
        self.timeout = httpx.Timeout(30.0)
        logger.info("üîß Initializing PF Analyzer (Tuned for Real-world usage)")
    
    async def download_images(self, urls: List[str]) -> List[bytes]:
        images = []
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            tasks = [self._download_single(client, url) for url in urls]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            for result in results:
                if result and not isinstance(result, Exception):
                    images.append(result)
        if not images: raise ValueError("No images downloaded")
        return images
    
    async def _download_single(self, client: httpx.AsyncClient, url: str) -> bytes:
        try:
            resp = await client.get(url); resp.raise_for_status(); return resp.content
        except: return None

    def _calculate_curvature(self, contour):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Curvature ‡πÇ‡∏î‡∏¢‡∏•‡∏î Noise ‡∏Ç‡∏≠‡∏á‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏Å‡πà‡∏≠‡∏ô"""
        pts = contour.squeeze().astype(float)
        if len(pts) < 3: return np.array([0.0])
        
        x = pts[:, 0]
        y = pts[:, 1]
        
        # ‡πÉ‡∏ä‡πâ Gradient ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏ô‡∏∏‡∏û‡∏±‡∏ô‡∏ò‡πå
        dx = np.gradient(x)
        dy = np.gradient(y)
        ddx = np.gradient(dx)
        ddy = np.gradient(dy)
        
        numerator = dx * ddy - dy * ddx
        denominator = np.power(dx**2 + dy**2, 1.5)
        
        # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏≤‡∏£‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏î‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (Clip ‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÇ‡∏ï‡πà‡∏á)
        curvature = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator!=0)
        curvature = np.clip(curvature, -0.5, 0.5) # Limit curvature ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô‡∏à‡∏≤‡∏Å Noise
        
        return curvature

    def analyze_foot_structure(self, images: List[bytes]) -> Dict[str, Any]:
        logger.info(f"üîç Analyzing...")
        
        if not images: raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")

        try:
            # 1. Prepare
            nparr = np.frombuffer(images[0], np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            # üî¥ ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏•‡∏á: ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏õ‡∏µ 2018 ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÑ‡∏°‡πà‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å
            # ‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 400px ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ P (Perimeter) ‡πÑ‡∏°‡πà‡∏™‡∏π‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏à‡∏ô‡∏â‡∏∏‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡πà‡∏ß‡∏á
            target_height = 400 
            h, w = img.shape[:2]
            scale = target_height / h
            new_w = int(w * scale)
            img = cv2.resize(img, (new_w, target_height))
            
            # 2. Pre-processing
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° Blur ‡πÉ‡∏´‡πâ‡πÅ‡∏£‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏ö Texture ‡∏Å‡∏£‡∏∞‡∏î‡∏≤‡∏©
            blur = cv2.GaussianBlur(gray, (9, 9), 0) 
            _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            # 3. Contour & Smoothing
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if not contours: raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤")
            largest_contour = max(contours, key=cv2.contourArea)
            
            # üî¥ Smoothing Contour (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î): 
            # ‡πÉ‡∏ä‡πâ approxPolyDP ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏ö‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏´‡∏¢‡∏±‡∏Å‡πÜ ‡∏Ç‡∏≠‡∏á‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏õ
            # epsilon 0.002 ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏¢‡∏≠‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏î‡πâ 0.2% (‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏£‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏ö Noise)
            epsilon = 0.002 * cv2.arcLength(largest_contour, True)
            smooth_contour = cv2.approxPolyDP(largest_contour, epsilon, True)
            
            # ---------------------------------------------------------
            # Calculation (MBE + P)
            # ---------------------------------------------------------
            
            # P = ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏∏‡∏î * (pi/4) ‡∏ï‡∏≤‡∏°‡πÄ‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå
            # ‡πÅ‡∏ï‡πà‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤ smooth ‡πÅ‡∏•‡πâ‡∏ß ‡∏à‡∏∏‡∏î‡∏à‡∏∞‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ arcLength ‡πÅ‡∏ó‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ P ‡∏¢‡∏±‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏™‡πÄ‡∏Å‡∏•
            # ‡∏™‡∏π‡∏ï‡∏£ PDF: P = boundary_pixels * (pi/4) -> ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì arcLength * (pi/4)
            P = cv2.arcLength(smooth_contour, True) * (np.pi / 4)
            
            # MBE Calculation
            curvature = self._calculate_curvature(smooth_contour)
            MBE = np.mean(curvature ** 2)
            
            # Equation (6)
            # AHI = 0.4597 - (7.351e-5 * P) - (1050.964 * MBE)
            term_p = 7.351e-5 * P
            term_mbe = 1050.964 * MBE
            research_score = 0.4597 - term_p - term_mbe
            
            logger.info(f"üìä Score: {research_score:.4f} | P: {P:.1f} (Term: {term_p:.4f}) | MBE: {MBE:.6f} (Term: {term_mbe:.4f})")

            # ---------------------------------------------------------
            # Classification
            # ---------------------------------------------------------
            # High: <= 0.23 | Normal: 0.23-0.27 | Flat: >= 0.27
            
            if research_score <= 0.23:
                arch_type = "high"
                flex = 0.4
            elif research_score >= 0.27:
                arch_type = "flat"
                flex = 0.4
            else:
                arch_type = "normal"
                flex = 0.6
                
            # Auto-Detect Side
            M = cv2.moments(largest_contour)
            cx = int(M["m10"] / M["m00"]) if M["m00"] != 0 else 0
            detected_side = "left" if cx < (new_w // 2) else "right"

            return {
                "arch_type": arch_type,
                "detected_side": detected_side,
                "arch_height_ratio": float(research_score),
                "heel_alignment": "neutral",
                "foot_length_cm": 25.0,
                "foot_width_cm": 10.0,
                "pressure_points": {"heel": 0.5, "arch": 0.5, "ball": 0.5, "toes": 0.5},
                "flexibility_score": flex,
                "confidence": 0.90
            }

        except Exception as e:
            logger.error(f"‚ùå Analysis failed: {e}")
            raise ValueError(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")

    def assess_plantar_fasciitis(self, foot_analysis, questionnaire_score=0.0, bmi_score=0):
        # (‡∏Ñ‡∏á Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏ß‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
        logger.info(f"üè• Assessing... (Quiz: {questionnaire_score}, BMI: {bmi_score})")
        arch_type = foot_analysis['arch_type']
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö Severity)
        scan_score = 50.0
        if arch_type == 'flat': scan_score = 80.0
        elif arch_type == 'high': scan_score = 70.0
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Severity ‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å Quiz + BMI
        total = questionnaire_score + bmi_score
        final_score = min((total / 20.0) * 100.0, 100.0)
        
        if final_score < 40: sev, sev_th = "low", "‡∏ï‡πà‡∏≥"
        elif final_score < 70: sev, sev_th = "medium", "‡∏Å‡∏•‡∏≤‡∏á"
        else: sev, sev_th = "high", "‡∏™‡∏π‡∏á"
        
        risk_factors = []
        if bmi_score >= 2: risk_factors.append("‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå")
        if arch_type == 'flat': risk_factors.append("‡πÄ‡∏ó‡πâ‡∏≤‡πÅ‡∏ö‡∏ô (Flat Arch)")
        if arch_type == 'high': risk_factors.append("‡∏≠‡∏∏‡πâ‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏™‡∏π‡∏á (High Arch)")
        
        return {
            "severity": sev, "severity_thai": sev_th, "score": round(final_score, 1),
            "arch_type": arch_type,
            "indicators": {
                "scan_part_score": round(scan_score/10, 1),
                "questionnaire_part_score": questionnaire_score,
                "bmi_score": float(bmi_score),
                "arch_collapse_score": scan_score,
                "heel_pain_index": 50.0,
                "flexibility_score": (1-foot_analysis['flexibility_score'])*100,
                "foot_alignment_score": 15.0
            },
            "risk_factors": risk_factors,
            "recommendations": self._generate_recommendations(sev, arch_type)
        }

    def _generate_recommendations(self, severity, arch_type):
        recs = ["‡∏Ñ‡∏ß‡∏£‡∏™‡∏ß‡∏°‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"]
        if arch_type == "flat": recs.append("‡πÉ‡∏ä‡πâ‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ Arch Support")
        elif arch_type == "high": recs.append("‡πÉ‡∏ä‡πâ‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÅ‡∏£‡∏á‡∏Å‡∏£‡∏∞‡πÅ‡∏ó‡∏Å‡πÑ‡∏î‡πâ‡∏î‡∏µ (Cushioning)")
        if severity == "high": recs.append("‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
        return recs

# import httpx
# import asyncio
# from typing import List, Dict, Any
# import logging
# import numpy as np
# import cv2
# import tensorflow as tf  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ TensorFlow
# import os

# logger = logging.getLogger(__name__)

# class PlantarFasciitisAnalyzer:
#     def __init__(self):
#         self.timeout = httpx.Timeout(30.0)
#         logger.info("üîß Initializing PF Analyzer (Deep Learning Mode)")
        
#         # 1. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏õ‡∏ß‡∏≤‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå services ‡∏´‡∏£‡∏∑‡∏≠ models)
#         model_path = "services/foot_segmentation_model.h5" 
        
#         if os.path.exists(model_path):
#             logger.info(f"üß† Loading AI Model from {model_path}...")
#             self.model = tf.keras.models.load_model(model_path)
#             logger.info("‚úÖ AI Model Loaded Successfully")
#         else:
#             logger.error(f"‚ùå Model file not found at {model_path}")
#             self.model = None # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

#     async def download_images(self, urls: List[str]) -> List[bytes]:
#         # (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)
#         images = []
#         async with httpx.AsyncClient(timeout=self.timeout) as client:
#             tasks = [self._download_single(client, url) for url in urls]
#             results = await asyncio.gather(*tasks, return_exceptions=True)
#             for result in results:
#                 if result and not isinstance(result, Exception):
#                     images.append(result)
#         if not images: raise ValueError("No images downloaded")
#         return images

#     async def _download_single(self, client: httpx.AsyncClient, url: str) -> bytes:
#         # (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
#         try:
#             resp = await client.get(url); resp.raise_for_status(); return resp.content
#         except: return None

#     def analyze_foot_structure(self, images: List[bytes]) -> Dict[str, Any]:
#         logger.info(f"üîç Analyzing images with AI...")
        
#         if not images: raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
#         if self.model is None: raise ValueError("‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Model)")

#         try:
#             # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏†‡∏≤‡∏û
#             nparr = np.frombuffer(images[0], np.uint8)
#             original_img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
#             if original_img is None: raise ValueError("‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢")

#             # 2. Preprocess ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö AI (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô)
#             # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏¢‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô 128x128, Normalize 0-1
#             IMG_SIZE = 128 
#             img_resized = cv2.resize(original_img, (IMG_SIZE, IMG_SIZE))
#             img_input = img_resized / 255.0  # Normalize
#             img_input = np.expand_dims(img_input, axis=0) # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô (1, 128, 128, 3)

#             # 3. ‡πÉ‡∏´‡πâ AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Segmentation)
#             # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Probability Map) ‡∏Ñ‡πà‡∏≤ 0.0-1.0
#             prediction = self.model.predict(img_input, verbose=0)
            
#             # 4. ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Mask (‡∏Ç‡∏≤‡∏ß-‡∏î‡∏≥)
#             mask = prediction[0] # ‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏£‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
#             mask = (mask > 0.5).astype(np.uint8) * 255 # ‡∏ñ‡πâ‡∏≤‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏Å‡∏¥‡∏ô 50% ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß (255)
            
#             # ‡∏Ç‡∏¢‡∏≤‡∏¢ Mask ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏ó‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏à‡∏£‡∏¥‡∏á
#             original_h, original_w = original_img.shape[:2]
#             full_size_mask = cv2.resize(mask, (original_w, original_h), interpolation=cv2.INTER_NEAREST)

#             # ---------------------------------------------------------
#             # 5. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Arch Index ‡∏à‡∏≤‡∏Å Mask ‡∏Ç‡∏≠‡∏á AI (Logic ‡πÄ‡∏î‡∏¥‡∏°)
#             # ---------------------------------------------------------
#             # ‡∏´‡∏≤ Contour ‡∏à‡∏≤‡∏Å Mask ‡∏ó‡∏µ‡πà AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡πâ
#             contours, _ = cv2.findContours(full_size_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
#             if not contours:
#                 raise ValueError("AI ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û (‡∏•‡∏≠‡∏á‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)")
            
#             largest_contour = max(contours, key=cv2.contourArea)
#             x, y, w, h = cv2.boundingRect(largest_contour)
            
#             # ‡∏ï‡∏±‡∏î Mask ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤
#             foot_roi = full_size_mask[y:y+h, x:x+w]
            
#             # ‡πÅ‡∏ö‡πà‡∏á 3 ‡∏™‡πà‡∏ß‡∏ô (‡∏ï‡∏±‡∏î‡∏ô‡∏¥‡πâ‡∏ß‡πÄ‡∏ó‡πâ‡∏≤ 20%)
#             foot_len = h
#             toes_len = int(foot_len * 0.20)
#             sole_len = foot_len - toes_len
#             section_h = sole_len // 3
#             start_y = toes_len
            
#             # ‡∏ï‡∏±‡∏î‡πÅ‡∏ö‡πà‡∏á
#             region_b = foot_roi[start_y + section_h : start_y + (2*section_h), :] # ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏•‡∏≤‡∏á
            
#             # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
#             # ‡πÄ‡∏£‡∏≤‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å Mask ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÄ‡∏•‡∏¢ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á threshold ‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ AI ‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥‡πÅ‡∏•‡πâ‡∏ß)
#             area_a = cv2.countNonZero(foot_roi[start_y + (2*section_h):, :])
#             area_b = cv2.countNonZero(region_b)
#             area_c = cv2.countNonZero(foot_roi[start_y : start_y + section_h, :])
            
#             total_area = area_a + area_b + area_c
#             if total_area == 0: raise ValueError("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå")
            
#             arch_index = area_b / total_area
#             logger.info(f"ü§ñ AI Arch Index: {arch_index:.4f}")

#             # 6. ‡πÅ‡∏õ‡∏•‡∏ú‡∏• (‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÄ‡∏î‡∏¥‡∏°)
#             if arch_index < 0.21:
#                 arch_type, heel_p, flex = "high", 0.8, 0.4
#             elif arch_index > 0.28:
#                 arch_type, heel_p, flex = "flat", 0.6, 0.4
#             else:
#                 arch_type, heel_p, flex = "normal", 0.5, 0.6

#             return {
#                 "arch_type": arch_type,
#                 "arch_height_ratio": float(arch_index),
#                 "heel_alignment": "neutral",
#                 "foot_length_cm": 25.0, "foot_width_cm": 10.0,
#                 "pressure_points": {"heel": heel_p, "arch": 0.5, "ball": 0.6, "toes": 0.4},
#                 "flexibility_score": flex,
#                 "confidence": 0.98, # ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ä‡πâ AI
#                 "method": "deep_learning_unet"
#             }

#         except Exception as e:
#             logger.error(f"‚ùå AI Analysis failed: {e}")
#             raise ValueError(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• AI: {str(e)}")
    
#     def assess_plantar_fasciitis(self, foot_analysis: Dict[str, Any], questionnaire_score: float = 0.0) -> Dict[str, Any]:
#         # (‡∏Ñ‡∏á Logic ‡∏™‡πà‡∏ß‡∏ô assess_plantar_fasciitis ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ)
#         # ... Copy ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏™‡πà‡∏ß‡∏ô assess_plantar_fasciitis ‡∏°‡∏≤‡πÅ‡∏õ‡∏∞‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ...
        
#         # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏ú‡∏°‡πÅ‡∏õ‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏Å‡πä‡∏≠‡∏õ‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö
        
#         logger.info(f"üè• Assessing plantar fasciitis... (Questionnaire: {questionnaire_score}/10)")
        
#         arch_type = foot_analysis['arch_type']
#         pressure = foot_analysis['pressure_points']
#         flexibility = foot_analysis['flexibility_score']
        
#         indicators = {}
        
#         # 1. Arch Collapse Score
#         if arch_type == "flat": indicators['arch_collapse_score'] = 75.0
#         elif arch_type == "high": indicators['arch_collapse_score'] = 40.0
#         else: indicators['arch_collapse_score'] = 20.0
        
#         # 2. Heel Pain Index
#         indicators['heel_pain_index'] = pressure['heel'] * 100
        
#         # 3. Pressure Distribution
#         pressure_values = list(pressure.values())
#         pressure_std = self._calculate_std(pressure_values)
#         indicators['pressure_distribution_score'] = pressure_std * 150
        
#         # 4. Foot Alignment Score
#         indicators['foot_alignment_score'] = 15.0 if foot_analysis['heel_alignment'] == "neutral" else 60.0
        
#         # 5. Flexibility Score
#         indicators['flexibility_score'] = (1 - flexibility) * 100
        
#         weights = {
#             'arch_collapse_score': 0.30,
#             'heel_pain_index': 0.25,
#             'pressure_distribution_score': 0.20,
#             'foot_alignment_score': 0.15,
#             'flexibility_score': 0.10
#         }
        
#         scan_score_raw = sum(indicators[key] * weight for key, weight in weights.items())
#         scan_score_10 = scan_score_raw / 10.0
#         total_score_20 = scan_score_10 + questionnaire_score
#         final_pf_score = (total_score_20 / 20.0) * 100.0
        
#         if final_pf_score < 40: severity, severity_thai = "low", "‡∏ï‡πà‡∏≥"
#         elif final_pf_score < 70: severity, severity_thai = "medium", "‡∏Å‡∏•‡∏≤‡∏á"
#         else: severity, severity_thai = "high", "‡∏™‡∏π‡∏á"
        
#         risk_factors = []
#         if arch_type == "flat": risk_factors.append("‡πÄ‡∏ó‡πâ‡∏≤‡πÅ‡∏ö‡∏ô (Flat feet)")
#         if arch_type == "high": risk_factors.append("‡πÇ‡∏Ñ‡πâ‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏™‡∏π‡∏á (High arch)")
#         if pressure['heel'] > 0.7: risk_factors.append("‡πÅ‡∏£‡∏á‡∏Å‡∏î‡∏™‡πâ‡∏ô‡πÄ‡∏ó‡πâ‡∏≤‡∏™‡∏π‡∏á")
#         if flexibility < 0.5: risk_factors.append("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏ô‡πâ‡∏≠‡∏¢")
#         if pressure_std > 0.25: risk_factors.append("‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•")
        
#         recommendations = self._generate_recommendations(severity, arch_type)
        
#         indicators['scan_part_score'] = round(scan_score_10, 1)
#         indicators['questionnaire_part_score'] = round(questionnaire_score, 1)
        
#         return {
#             "severity": severity,
#             "severity_thai": severity_thai,
#             "score": round(final_pf_score, 1),
#             "arch_type": arch_type,
#             "indicators": {k: round(v, 1) for k, v in indicators.items()},
#             "risk_factors": risk_factors,
#             "recommendations": recommendations
#         }
    
#     def _calculate_std(self, v): return np.std(v) if len(v) > 1 else 0
    
#     def _generate_recommendations(self, severity: str, arch_type: str) -> List[str]:
#         recommendations = []
#         if severity == "high":
#             recommendations.extend(["‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡πá‡∏ß", "‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏ô‡∏≤‡∏ô", "‡πÉ‡∏ä‡πâ‡πÅ‡∏ú‡πà‡∏ô‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏û‡∏¥‡πÄ‡∏®‡∏© (Orthotic insole)"])
#         if severity == "medium":
#             recommendations.extend(["‡∏Ñ‡∏ß‡∏£‡∏û‡∏±‡∏Å‡πÄ‡∏ó‡πâ‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠", "‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏¢‡∏∑‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏ó‡πâ‡∏≤", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏î‡∏µ"])
#         if severity == "low":
#             recommendations.extend(["‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Å‡∏•‡πâ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏ó‡πâ‡∏≤", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÄ‡∏ó‡πâ‡∏≤"])
#         if arch_type == "flat": recommendations.append("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ arch support ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á")
#         elif arch_type == "high": recommendations.append("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ cushioning ‡∏î‡∏µ")
#         return recommendations