"""
Plantar Fasciitis Analyzer (Research Based)
‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: Automated Spatial Pattern Analysis for Identification of Foot Arch Height (Lucas et al., 2018)
Method: Mean Bending Energy (MBE) + Perimeter (P) Regression Model
"""

import httpx
import asyncio
from typing import List, Dict, Any
import logging
import numpy as np
import cv2

logger = logging.getLogger(__name__)

class PlantarFasciitisAnalyzer:
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏ä‡πâ‡∏≥‡∏à‡∏≤‡∏Å‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤ (‡πÉ‡∏ä‡πâ‡∏™‡∏π‡∏ï‡∏£ MBE + Perimeter ‡∏à‡∏≤‡∏Å‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢)"""
    
    def __init__(self):
        self.timeout = httpx.Timeout(30.0)
        logger.info("üîß Initializing PF Analyzer (Research Method: MBE + P)")
    
    async def download_images(self, urls: List[str]) -> List[bytes]:
        images = []
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            tasks = [self._download_single(client, url) for url in urls]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.warning(f"‚ö†Ô∏è Failed to download image {i+1}: {result}")
                    continue
                if result:
                    images.append(result)
        if not images:
            raise ValueError("No images downloaded")
        return images
    
    async def _download_single(self, client: httpx.AsyncClient, url: str) -> bytes:
        try:
            response = await client.get(url)
            response.raise_for_status()
            return response.content
        except Exception as e:
            logger.error(f"Failed to download {url}: {e}")
            return None

    def _calculate_curvature(self, contour):
        """
        ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏á (Curvature) ‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏≠‡∏ö‡∏£‡∏π‡∏õ
        ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡∏´‡∏≤ Mean Bending Energy (MBE)
        """
        # contour shape: (N, 1, 2)
        pts = contour.squeeze().astype(float)
        x = pts[:, 0]
        y = pts[:, 1]
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏ô‡∏∏‡∏û‡∏±‡∏ô‡∏ò‡πå (Derivatives) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Gradient
        dx = np.gradient(x)
        dy = np.gradient(y)
        ddx = np.gradient(dx)
        ddy = np.gradient(dy)
        
        # ‡∏™‡∏π‡∏ï‡∏£ Curvature: k = (x'y'' - y'x'') / (x'^2 + y'^2)^1.5
        numerator = dx * ddy - dy * ddx
        denominator = np.power(dx**2 + dy**2, 1.5)
        
        # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏®‡∏π‡∏ô‡∏¢‡πå
        curvature = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator!=0)
        return curvature
    
    def analyze_foot_structure(self, images: List[bytes]) -> Dict[str, Any]:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤‡πÄ‡∏õ‡∏µ‡∏¢‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏°‡∏Å‡∏≤‡∏£ MBE + Perimeter
        ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (Auto-Detect Side)
        """
        logger.info(f"üîç Analyzing {len(images)} footprint images (Research Method)")
        
        if not images:
             raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
             
        try:
            # 1. ‡πÅ‡∏õ‡∏•‡∏á Bytes ‡πÄ‡∏õ‡πá‡∏ô OpenCV Image
            nparr = np.frombuffer(images[0], np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if img is None:
                raise ValueError("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ")

            # ‚úÖ Normalization: Resize ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (800px)
            # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å! ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢ (-7.351e-5 * P) ‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
            # ‡∏ñ‡πâ‡∏≤‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Ñ‡πà‡∏≤ P ‡∏à‡∏∞‡∏°‡∏´‡∏≤‡∏®‡∏≤‡∏•‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏•‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô
            target_height = 800
            h, w = img.shape[:2]
            scale = target_height / h
            new_w = int(w * scale)
            img = cv2.resize(img, (new_w, target_height))

            # ---------------------------------------------------------
            # 2. Pre-processing & Validation
            # ---------------------------------------------------------
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # Check Brightness
            mean_brightness = np.mean(gray)
            if mean_brightness < 40: raise ValueError("‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏∑‡∏î‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
            if mean_brightness > 250: raise ValueError("‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")

            # Blur & Threshold
            blur = cv2.GaussianBlur(gray, (5, 5), 0)
            _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            # Find Contour
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if not contours: raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û")
            largest_contour = max(contours, key=cv2.contourArea)
            
            # Sanity Check
            contour_area = cv2.contourArea(largest_contour)
            img_area = img.shape[0] * img.shape[1]
            if contour_area < 2000: raise ValueError("‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
            if (contour_area / img_area) > 0.90: raise ValueError("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÄ‡∏ï‡πá‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")

            # ---------------------------------------------------------
            # ü§ñ Feature: Auto-Detect Foot Side (Left/Right)
            # ---------------------------------------------------------
            M = cv2.moments(largest_contour)
            cx = int(M["m10"] / M["m00"]) if M["m00"] != 0 else 0
            center_line = img.shape[1] // 2
            
            # ‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ñ‡πà‡∏ß‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ã‡πâ‡∏≤‡∏¢ = ‡πÄ‡∏ó‡πâ‡∏≤‡∏ã‡πâ‡∏≤‡∏¢, ‡∏Ç‡∏ß‡∏≤ = ‡πÄ‡∏ó‡πâ‡∏≤‡∏Ç‡∏ß‡∏≤
            detected_side = "left" if cx < center_line else "right"
            logger.info(f"ü¶∂ Auto-detected Side: {detected_side.upper()} (Centroid X: {cx})")

            # ---------------------------------------------------------
            # üî¨ Research Method: Calculation (MBE + P)
            # ---------------------------------------------------------
            
            # 1. Perimeter (P): ‡∏ï‡∏≤‡∏° PDF ‡∏Ñ‡∏∑‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô pixel ‡∏Ç‡∏≠‡∏ö * (pi/4)
            # ‡πÉ‡∏ä‡πâ len(contour) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏∏‡∏î‡∏Ç‡∏≠‡∏ö
            num_boundary_pixels = len(largest_contour)
            P = num_boundary_pixels * (np.pi / 4)
            
            # 2. Mean Bending Energy (MBE): ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á curvature^2
            curvature = self._calculate_curvature(largest_contour)
            MBE = np.mean(curvature ** 2)
            
            # 3. Apply Equation (6) ‡∏à‡∏≤‡∏Å PDF
            # AHI = (-7.351e-5 * P) - (1050.964 * MBE) + 0.4597
            research_score = (-7.351e-5 * P) - (1050.964 * MBE) + 0.4597
            
            logger.info(f"üìä Research Score: {research_score:.4f} (P={P:.1f}, MBE={MBE:.6f})")

            # ---------------------------------------------------------
            # 4. Classification (Cut-offs from Figure 6)
            # ---------------------------------------------------------
            # High Arch: <= 0.23
            # Normal: 0.23 - 0.27
            # Low Arch: >= 0.27
            
            if research_score <= 0.23:
                arch_type = "high"
                pressure_dist = {"heel": 0.8, "arch": 0.1, "ball": 0.6, "toes": 0.4}
                flexibility = 0.4
            elif research_score >= 0.27:
                arch_type = "flat"
                pressure_dist = {"heel": 0.6, "arch": 0.8, "ball": 0.6, "toes": 0.4}
                flexibility = 0.4
            else:
                arch_type = "normal"
                pressure_dist = {"heel": 0.5, "arch": 0.4, "ball": 0.6, "toes": 0.6}
                flexibility = 0.6

            return {
                "arch_type": arch_type,
                "detected_side": detected_side,  # ‚úÖ ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ
                "arch_height_ratio": float(research_score), # ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏ó‡∏ô Ratio ‡πÄ‡∏î‡∏¥‡∏°
                "heel_alignment": "neutral",
                "foot_length_cm": 25.0,
                "foot_width_cm": 10.0,
                "pressure_points": pressure_dist,
                "flexibility_score": flexibility,
                "confidence": 0.90,
                "method": "MBE_Perimeter_Regression"
            }

        except Exception as e:
            logger.error(f"‚ùå Analysis failed: {e}")
            raise ValueError(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")

    def _get_fallback_analysis(self):
        return {
            "arch_type": "normal",
            "arch_height_ratio": 0.25,
            "heel_alignment": "neutral",
            "foot_length_cm": 25.0,
            "foot_width_cm": 10.0,
            "pressure_points": { "heel": 0.5, "arch": 0.5, "ball": 0.5, "toes": 0.5 },
            "flexibility_score": 0.5
        }  
    
    def assess_plantar_fasciitis(
        self,
        foot_analysis: Dict[str, Any],
        questionnaire_score: float = 0.0,
        bmi_score: int = 0
    ) -> Dict[str, Any]:
        """
        ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏≠‡∏á‡∏ä‡πâ‡∏≥ (‡∏™‡∏π‡∏ï‡∏£‡πÉ‡∏´‡∏°‡πà: Quiz + BMI)
        """
        logger.info(f"üè• Assessing plantar fasciitis... (Quiz: {questionnaire_score}, BMI: {bmi_score})")
        
        arch_type = foot_analysis['arch_type']
        pressure = foot_analysis['pressure_points']
        flexibility = foot_analysis['flexibility_score']
        
        # --- 1. ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏™‡πÅ‡∏Å‡∏ô (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏¥‡∏î‡∏£‡∏ß‡∏°‡πÉ‡∏ô Severity ‡∏´‡∏•‡∏±‡∏Å) ---
        indicators = {}
        
        # Mapping Score ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πÄ‡∏Å‡∏• 0-100 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Frontend (‡πÅ‡∏Ñ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•)
        scan_score_raw = 50.0 # Normal
        if arch_type == "flat": scan_score_raw = 80.0
        elif arch_type == "high": scan_score_raw = 70.0
        
        # --- 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏£‡∏ß‡∏° (Questionnaire + BMI) ---
        # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠ 20 (Quiz ~17 + BMI 3)
        total_score_raw = questionnaire_score + bmi_score
        max_possible_score = 20.0 
        
        final_pf_score = (total_score_raw / max_possible_score) * 100.0
        if final_pf_score > 100: final_pf_score = 100.0
        
        # --- 3. ‡∏ï‡∏±‡∏î‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á ---
        if final_pf_score < 40: severity, severity_thai = "low", "‡∏ï‡πà‡∏≥"
        elif final_pf_score < 70: severity, severity_thai = "medium", "‡∏Å‡∏•‡∏≤‡∏á"
        else: severity, severity_thai = "high", "‡∏™‡∏π‡∏á"
        
        # --- 4. ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ---
        risk_factors = []
        if bmi_score == 3: risk_factors.append("‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå (Obesity)")
        elif bmi_score == 2: risk_factors.append("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô (Overweight)")
            
        if arch_type == "flat": risk_factors.append("‡πÄ‡∏ó‡πâ‡∏≤‡πÅ‡∏ö‡∏ô (Research Criteria)")
        if arch_type == "high": risk_factors.append("‡∏≠‡∏∏‡πâ‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏™‡∏π‡∏á (Research Criteria)")
        if flexibility < 0.5: risk_factors.append("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏ô‡πâ‡∏≠‡∏¢")
        
        recommendations = self._generate_recommendations(severity, arch_type)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏•‡∏á indicators
        indicators['scan_part_score'] = round(scan_score_raw / 10.0, 1) # ‡πÄ‡∏ï‡πá‡∏° 10
        indicators['questionnaire_part_score'] = round(questionnaire_score, 1)
        indicators['bmi_score'] = float(bmi_score)
        
        # ‡∏Ñ‡πà‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà Frontend ‡∏≠‡∏≤‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ
        indicators['arch_collapse_score'] = scan_score_raw
        indicators['heel_pain_index'] = pressure['heel'] * 100
        indicators['flexibility_score'] = (1 - flexibility) * 100
        indicators['foot_alignment_score'] = 15.0 # default
        
        return {
            "severity": severity,
            "severity_thai": severity_thai,
            "score": round(final_pf_score, 1),
            "arch_type": arch_type,
            "indicators": {k: round(v, 1) for k, v in indicators.items()},
            "risk_factors": risk_factors,
            "recommendations": recommendations
        }
    
    def _calculate_std(self, values: List[float]) -> float:
        n = len(values)
        if n < 2: return 0
        mean = sum(values) / n
        variance = sum((x - mean) ** 2 for x in values) / n
        return variance ** 0.5
    
    def _generate_recommendations(self, severity: str, arch_type: str) -> List[str]:
        recommendations = []
        if severity == "high":
            recommendations.extend(["‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡πá‡∏ß", "‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏ô‡∏≤‡∏ô", "‡πÉ‡∏ä‡πâ‡πÅ‡∏ú‡πà‡∏ô‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏û‡∏¥‡πÄ‡∏®‡∏© (Orthotic insole)"])
        if severity == "medium":
            recommendations.extend(["‡∏Ñ‡∏ß‡∏£‡∏û‡∏±‡∏Å‡πÄ‡∏ó‡πâ‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠", "‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏¢‡∏∑‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏ó‡πâ‡∏≤", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏î‡∏µ"])
        if severity == "low":
            recommendations.extend(["‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Å‡∏•‡πâ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏ó‡πâ‡∏≤", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÄ‡∏ó‡πâ‡∏≤"])
        if arch_type == "flat": recommendations.append("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ arch support ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á")
        elif arch_type == "high": recommendations.append("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ cushioning ‡∏î‡∏µ")
        return recommendations

# import httpx
# import asyncio
# from typing import List, Dict, Any
# import logging
# import numpy as np
# import cv2
# import tensorflow as tf  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ TensorFlow
# import os

# logger = logging.getLogger(__name__)

# class PlantarFasciitisAnalyzer:
#     def __init__(self):
#         self.timeout = httpx.Timeout(30.0)
#         logger.info("üîß Initializing PF Analyzer (Deep Learning Mode)")
        
#         # 1. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏õ‡∏ß‡∏≤‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå services ‡∏´‡∏£‡∏∑‡∏≠ models)
#         model_path = "services/foot_segmentation_model.h5" 
        
#         if os.path.exists(model_path):
#             logger.info(f"üß† Loading AI Model from {model_path}...")
#             self.model = tf.keras.models.load_model(model_path)
#             logger.info("‚úÖ AI Model Loaded Successfully")
#         else:
#             logger.error(f"‚ùå Model file not found at {model_path}")
#             self.model = None # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

#     async def download_images(self, urls: List[str]) -> List[bytes]:
#         # (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)
#         images = []
#         async with httpx.AsyncClient(timeout=self.timeout) as client:
#             tasks = [self._download_single(client, url) for url in urls]
#             results = await asyncio.gather(*tasks, return_exceptions=True)
#             for result in results:
#                 if result and not isinstance(result, Exception):
#                     images.append(result)
#         if not images: raise ValueError("No images downloaded")
#         return images

#     async def _download_single(self, client: httpx.AsyncClient, url: str) -> bytes:
#         # (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
#         try:
#             resp = await client.get(url); resp.raise_for_status(); return resp.content
#         except: return None

#     def analyze_foot_structure(self, images: List[bytes]) -> Dict[str, Any]:
#         logger.info(f"üîç Analyzing images with AI...")
        
#         if not images: raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
#         if self.model is None: raise ValueError("‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Model)")

#         try:
#             # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏†‡∏≤‡∏û
#             nparr = np.frombuffer(images[0], np.uint8)
#             original_img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
#             if original_img is None: raise ValueError("‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢")

#             # 2. Preprocess ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö AI (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô)
#             # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏¢‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô 128x128, Normalize 0-1
#             IMG_SIZE = 128 
#             img_resized = cv2.resize(original_img, (IMG_SIZE, IMG_SIZE))
#             img_input = img_resized / 255.0  # Normalize
#             img_input = np.expand_dims(img_input, axis=0) # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô (1, 128, 128, 3)

#             # 3. ‡πÉ‡∏´‡πâ AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Segmentation)
#             # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Probability Map) ‡∏Ñ‡πà‡∏≤ 0.0-1.0
#             prediction = self.model.predict(img_input, verbose=0)
            
#             # 4. ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Mask (‡∏Ç‡∏≤‡∏ß-‡∏î‡∏≥)
#             mask = prediction[0] # ‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏£‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
#             mask = (mask > 0.5).astype(np.uint8) * 255 # ‡∏ñ‡πâ‡∏≤‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏Å‡∏¥‡∏ô 50% ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß (255)
            
#             # ‡∏Ç‡∏¢‡∏≤‡∏¢ Mask ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏ó‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏à‡∏£‡∏¥‡∏á
#             original_h, original_w = original_img.shape[:2]
#             full_size_mask = cv2.resize(mask, (original_w, original_h), interpolation=cv2.INTER_NEAREST)

#             # ---------------------------------------------------------
#             # 5. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Arch Index ‡∏à‡∏≤‡∏Å Mask ‡∏Ç‡∏≠‡∏á AI (Logic ‡πÄ‡∏î‡∏¥‡∏°)
#             # ---------------------------------------------------------
#             # ‡∏´‡∏≤ Contour ‡∏à‡∏≤‡∏Å Mask ‡∏ó‡∏µ‡πà AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡πâ
#             contours, _ = cv2.findContours(full_size_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
#             if not contours:
#                 raise ValueError("AI ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û (‡∏•‡∏≠‡∏á‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)")
            
#             largest_contour = max(contours, key=cv2.contourArea)
#             x, y, w, h = cv2.boundingRect(largest_contour)
            
#             # ‡∏ï‡∏±‡∏î Mask ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤
#             foot_roi = full_size_mask[y:y+h, x:x+w]
            
#             # ‡πÅ‡∏ö‡πà‡∏á 3 ‡∏™‡πà‡∏ß‡∏ô (‡∏ï‡∏±‡∏î‡∏ô‡∏¥‡πâ‡∏ß‡πÄ‡∏ó‡πâ‡∏≤ 20%)
#             foot_len = h
#             toes_len = int(foot_len * 0.20)
#             sole_len = foot_len - toes_len
#             section_h = sole_len // 3
#             start_y = toes_len
            
#             # ‡∏ï‡∏±‡∏î‡πÅ‡∏ö‡πà‡∏á
#             region_b = foot_roi[start_y + section_h : start_y + (2*section_h), :] # ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏•‡∏≤‡∏á
            
#             # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
#             # ‡πÄ‡∏£‡∏≤‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å Mask ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÄ‡∏•‡∏¢ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á threshold ‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ AI ‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥‡πÅ‡∏•‡πâ‡∏ß)
#             area_a = cv2.countNonZero(foot_roi[start_y + (2*section_h):, :])
#             area_b = cv2.countNonZero(region_b)
#             area_c = cv2.countNonZero(foot_roi[start_y : start_y + section_h, :])
            
#             total_area = area_a + area_b + area_c
#             if total_area == 0: raise ValueError("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏¢‡πÄ‡∏ó‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå")
            
#             arch_index = area_b / total_area
#             logger.info(f"ü§ñ AI Arch Index: {arch_index:.4f}")

#             # 6. ‡πÅ‡∏õ‡∏•‡∏ú‡∏• (‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÄ‡∏î‡∏¥‡∏°)
#             if arch_index < 0.21:
#                 arch_type, heel_p, flex = "high", 0.8, 0.4
#             elif arch_index > 0.28:
#                 arch_type, heel_p, flex = "flat", 0.6, 0.4
#             else:
#                 arch_type, heel_p, flex = "normal", 0.5, 0.6

#             return {
#                 "arch_type": arch_type,
#                 "arch_height_ratio": float(arch_index),
#                 "heel_alignment": "neutral",
#                 "foot_length_cm": 25.0, "foot_width_cm": 10.0,
#                 "pressure_points": {"heel": heel_p, "arch": 0.5, "ball": 0.6, "toes": 0.4},
#                 "flexibility_score": flex,
#                 "confidence": 0.98, # ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ä‡πâ AI
#                 "method": "deep_learning_unet"
#             }

#         except Exception as e:
#             logger.error(f"‚ùå AI Analysis failed: {e}")
#             raise ValueError(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• AI: {str(e)}")
    
#     def assess_plantar_fasciitis(self, foot_analysis: Dict[str, Any], questionnaire_score: float = 0.0) -> Dict[str, Any]:
#         # (‡∏Ñ‡∏á Logic ‡∏™‡πà‡∏ß‡∏ô assess_plantar_fasciitis ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ)
#         # ... Copy ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏™‡πà‡∏ß‡∏ô assess_plantar_fasciitis ‡∏°‡∏≤‡πÅ‡∏õ‡∏∞‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ...
        
#         # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏ú‡∏°‡πÅ‡∏õ‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏Å‡πä‡∏≠‡∏õ‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö
        
#         logger.info(f"üè• Assessing plantar fasciitis... (Questionnaire: {questionnaire_score}/10)")
        
#         arch_type = foot_analysis['arch_type']
#         pressure = foot_analysis['pressure_points']
#         flexibility = foot_analysis['flexibility_score']
        
#         indicators = {}
        
#         # 1. Arch Collapse Score
#         if arch_type == "flat": indicators['arch_collapse_score'] = 75.0
#         elif arch_type == "high": indicators['arch_collapse_score'] = 40.0
#         else: indicators['arch_collapse_score'] = 20.0
        
#         # 2. Heel Pain Index
#         indicators['heel_pain_index'] = pressure['heel'] * 100
        
#         # 3. Pressure Distribution
#         pressure_values = list(pressure.values())
#         pressure_std = self._calculate_std(pressure_values)
#         indicators['pressure_distribution_score'] = pressure_std * 150
        
#         # 4. Foot Alignment Score
#         indicators['foot_alignment_score'] = 15.0 if foot_analysis['heel_alignment'] == "neutral" else 60.0
        
#         # 5. Flexibility Score
#         indicators['flexibility_score'] = (1 - flexibility) * 100
        
#         weights = {
#             'arch_collapse_score': 0.30,
#             'heel_pain_index': 0.25,
#             'pressure_distribution_score': 0.20,
#             'foot_alignment_score': 0.15,
#             'flexibility_score': 0.10
#         }
        
#         scan_score_raw = sum(indicators[key] * weight for key, weight in weights.items())
#         scan_score_10 = scan_score_raw / 10.0
#         total_score_20 = scan_score_10 + questionnaire_score
#         final_pf_score = (total_score_20 / 20.0) * 100.0
        
#         if final_pf_score < 40: severity, severity_thai = "low", "‡∏ï‡πà‡∏≥"
#         elif final_pf_score < 70: severity, severity_thai = "medium", "‡∏Å‡∏•‡∏≤‡∏á"
#         else: severity, severity_thai = "high", "‡∏™‡∏π‡∏á"
        
#         risk_factors = []
#         if arch_type == "flat": risk_factors.append("‡πÄ‡∏ó‡πâ‡∏≤‡πÅ‡∏ö‡∏ô (Flat feet)")
#         if arch_type == "high": risk_factors.append("‡πÇ‡∏Ñ‡πâ‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏™‡∏π‡∏á (High arch)")
#         if pressure['heel'] > 0.7: risk_factors.append("‡πÅ‡∏£‡∏á‡∏Å‡∏î‡∏™‡πâ‡∏ô‡πÄ‡∏ó‡πâ‡∏≤‡∏™‡∏π‡∏á")
#         if flexibility < 0.5: risk_factors.append("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏ô‡πâ‡∏≠‡∏¢")
#         if pressure_std > 0.25: risk_factors.append("‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•")
        
#         recommendations = self._generate_recommendations(severity, arch_type)
        
#         indicators['scan_part_score'] = round(scan_score_10, 1)
#         indicators['questionnaire_part_score'] = round(questionnaire_score, 1)
        
#         return {
#             "severity": severity,
#             "severity_thai": severity_thai,
#             "score": round(final_pf_score, 1),
#             "arch_type": arch_type,
#             "indicators": {k: round(v, 1) for k, v in indicators.items()},
#             "risk_factors": risk_factors,
#             "recommendations": recommendations
#         }
    
#     def _calculate_std(self, v): return np.std(v) if len(v) > 1 else 0
    
#     def _generate_recommendations(self, severity: str, arch_type: str) -> List[str]:
#         recommendations = []
#         if severity == "high":
#             recommendations.extend(["‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡πá‡∏ß", "‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏ô‡∏≤‡∏ô", "‡πÉ‡∏ä‡πâ‡πÅ‡∏ú‡πà‡∏ô‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏û‡∏¥‡πÄ‡∏®‡∏© (Orthotic insole)"])
#         if severity == "medium":
#             recommendations.extend(["‡∏Ñ‡∏ß‡∏£‡∏û‡∏±‡∏Å‡πÄ‡∏ó‡πâ‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠", "‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏¢‡∏∑‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏ó‡πâ‡∏≤", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏î‡∏µ"])
#         if severity == "low":
#             recommendations.extend(["‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Å‡∏•‡πâ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏ó‡πâ‡∏≤", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÄ‡∏ó‡πâ‡∏≤"])
#         if arch_type == "flat": recommendations.append("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ arch support ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á")
#         elif arch_type == "high": recommendations.append("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ cushioning ‡∏î‡∏µ")
#         return recommendations